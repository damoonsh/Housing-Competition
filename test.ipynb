{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "# Retrieve Data\n",
    "data = retrieve_data()\n",
    "train = data['train']\n",
    "test = data['test']\n",
    "train_num = data['train_num']\n",
    "y_feature = 'SalePrice'\n",
    "\n",
    "train = train.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data now\n",
    "test_cat = data['test_cat']\n",
    "# Get the dics for the missing values in the test dataset\n",
    "# Sicne there are no 'SalePrice' features in the test set\n",
    "# then we should apply the values for train to test\n",
    "dics = {}\n",
    "for feat in test_cat:\n",
    "    dics[feat] = rank_categorical_values(train, feat)\n",
    "    test[feat] = impute_rank_weight(test[feat].copy(), dics[feat][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical encoding for test data:\n",
    "# LotFrontage and MasVnrArea should equal zero when na \n",
    "zeros = [\n",
    "    'LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',  \n",
    "    'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageCars'\n",
    "]\n",
    "\n",
    "imp = ['GarageYrBlt', 'GarageArea']\n",
    "\n",
    "for feat in zeros:\n",
    "    test[feat] = test[feat].fillna(0)\n",
    "    \n",
    "for im in imp:\n",
    "    test[im] = test[im].fillna(test[im].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute both train and test data\n",
    "# 1. encode categorical\n",
    "train = encode_categorical(train.copy(), data['train_cat'].copy(), y_feature='SalePrice')\n",
    "# 2. impute numericals\n",
    "train = impute_numerical(train)\n",
    "# 3. randomize the data\n",
    "normalize_train = normalize(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breaking the x and y splits:\n",
    "# Finding the features\n",
    "features = normalize_train.corr()['SalePrice'].nlargest(9)[1:].keys().to_list()\n",
    "X = normalize_train[features]\n",
    "y = normalize_train[y_feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "devs = []\n",
    "for i in range(10):\n",
    "    dev_data = train.sample(n=438, random_state=i)\n",
    "    dev_x = dev_data[features]\n",
    "    dev_y = dev_data[y_feature]\n",
    "    devs.append((dev_x, dev_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if the imputation worked\n",
    "True in normalize_train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073350</td>\n",
       "      <td>0.387032</td>\n",
       "      <td>0.212804</td>\n",
       "      <td>-0.207071</td>\n",
       "      <td>0.064216</td>\n",
       "      <td>0.223014</td>\n",
       "      <td>-0.736346</td>\n",
       "      <td>-0.057799</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>-0.345831</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068668</td>\n",
       "      <td>-0.04466</td>\n",
       "      <td>0.445272</td>\n",
       "      <td>0.168335</td>\n",
       "      <td>-0.087658</td>\n",
       "      <td>-1.598563</td>\n",
       "      <td>0.138730</td>\n",
       "      <td>-0.255454</td>\n",
       "      <td>-0.195569</td>\n",
       "      <td>0.347154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.872264</td>\n",
       "      <td>0.387032</td>\n",
       "      <td>0.645526</td>\n",
       "      <td>-0.091855</td>\n",
       "      <td>0.064216</td>\n",
       "      <td>0.223014</td>\n",
       "      <td>-0.736346</td>\n",
       "      <td>-0.057799</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>-0.259309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068668</td>\n",
       "      <td>-0.04466</td>\n",
       "      <td>0.445272</td>\n",
       "      <td>0.168335</td>\n",
       "      <td>-0.087658</td>\n",
       "      <td>-0.488943</td>\n",
       "      <td>-0.614228</td>\n",
       "      <td>-0.255454</td>\n",
       "      <td>-0.195569</td>\n",
       "      <td>0.007286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073350</td>\n",
       "      <td>0.387032</td>\n",
       "      <td>0.299349</td>\n",
       "      <td>0.073455</td>\n",
       "      <td>0.064216</td>\n",
       "      <td>0.223014</td>\n",
       "      <td>1.146920</td>\n",
       "      <td>-0.057799</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>-0.345831</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068668</td>\n",
       "      <td>-0.04466</td>\n",
       "      <td>0.445272</td>\n",
       "      <td>0.168335</td>\n",
       "      <td>-0.087658</td>\n",
       "      <td>0.990552</td>\n",
       "      <td>0.138730</td>\n",
       "      <td>-0.255454</td>\n",
       "      <td>-0.195569</td>\n",
       "      <td>0.535970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.309753</td>\n",
       "      <td>0.387032</td>\n",
       "      <td>0.068564</td>\n",
       "      <td>-0.096864</td>\n",
       "      <td>0.064216</td>\n",
       "      <td>0.223014</td>\n",
       "      <td>1.146920</td>\n",
       "      <td>-0.057799</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.060970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068668</td>\n",
       "      <td>-0.04466</td>\n",
       "      <td>0.445272</td>\n",
       "      <td>0.168335</td>\n",
       "      <td>-0.087658</td>\n",
       "      <td>-1.598563</td>\n",
       "      <td>-1.367186</td>\n",
       "      <td>-0.255454</td>\n",
       "      <td>-1.176173</td>\n",
       "      <td>-0.515105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073350</td>\n",
       "      <td>0.387032</td>\n",
       "      <td>0.760919</td>\n",
       "      <td>0.375020</td>\n",
       "      <td>0.064216</td>\n",
       "      <td>0.223014</td>\n",
       "      <td>1.146920</td>\n",
       "      <td>-0.057799</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>-0.259309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068668</td>\n",
       "      <td>-0.04466</td>\n",
       "      <td>0.445272</td>\n",
       "      <td>0.168335</td>\n",
       "      <td>-0.087658</td>\n",
       "      <td>2.100173</td>\n",
       "      <td>0.138730</td>\n",
       "      <td>-0.255454</td>\n",
       "      <td>-0.195569</td>\n",
       "      <td>0.869545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  MSZoning  LotFrontage   LotArea    Street     Alley  LotShape  \\\n",
       "0    0.073350  0.387032     0.212804 -0.207071  0.064216  0.223014 -0.736346   \n",
       "1   -0.872264  0.387032     0.645526 -0.091855  0.064216  0.223014 -0.736346   \n",
       "2    0.073350  0.387032     0.299349  0.073455  0.064216  0.223014  1.146920   \n",
       "3    0.309753  0.387032     0.068564 -0.096864  0.064216  0.223014  1.146920   \n",
       "4    0.073350  0.387032     0.760919  0.375020  0.064216  0.223014  1.146920   \n",
       "\n",
       "   LandContour  Utilities  LotConfig  ...  PoolArea   PoolQC     Fence  \\\n",
       "0    -0.057799   0.026171  -0.345831  ... -0.068668 -0.04466  0.445272   \n",
       "1    -0.057799   0.026171  -0.259309  ... -0.068668 -0.04466  0.445272   \n",
       "2    -0.057799   0.026171  -0.345831  ... -0.068668 -0.04466  0.445272   \n",
       "3    -0.057799   0.026171   0.060970  ... -0.068668 -0.04466  0.445272   \n",
       "4    -0.057799   0.026171  -0.259309  ... -0.068668 -0.04466  0.445272   \n",
       "\n",
       "   MiscFeature   MiscVal    MoSold    YrSold  SaleType  SaleCondition  \\\n",
       "0     0.168335 -0.087658 -1.598563  0.138730 -0.255454      -0.195569   \n",
       "1     0.168335 -0.087658 -0.488943 -0.614228 -0.255454      -0.195569   \n",
       "2     0.168335 -0.087658  0.990552  0.138730 -0.255454      -0.195569   \n",
       "3     0.168335 -0.087658 -1.598563 -1.367186 -0.255454      -1.176173   \n",
       "4     0.168335 -0.087658  2.100173  0.138730 -0.255454      -0.195569   \n",
       "\n",
       "   SalePrice  \n",
       "0   0.347154  \n",
       "1   0.007286  \n",
       "2   0.535970  \n",
       "3  -0.515105  \n",
       "4   0.869545  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some categorical features in training data don't have nan's but\n",
    "# they do in test, hence the transform method of sklearn.simpleimputer will be used\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "missing_test = test[test.columns[test.isna().any()].tolist()]\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "imp_mean.fit(train[test.columns[test.isna().any()].tolist()])\n",
    "d = imp_mean.transform(np.array(missing_test))\n",
    "\n",
    "df = {}\n",
    "for feat in test.columns[test.isna().any()].tolist():\n",
    "    df[feat] = d[:, test.columns[test.isna().any()].tolist().index(feat)]\n",
    "test[test.columns[test.isna().any()].tolist()] = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True in list(test.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the normalized X_test\n",
    "X_test = normalize(test[features].copy())\n",
    "# Get the mean and std to remake the predicted values\n",
    "std = data['train'][y_feature].std()\n",
    "mean = data['train'][y_feature].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax does not make sense, drop out and batchnormalization works\n",
    "def build_model03():\n",
    "  model = keras.Sequential([\n",
    "    layers.InputLayer(input_shape=[len(X.keys())]),\n",
    "      \n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(64),\n",
    "    layers.BatchNormalization(),\n",
    "      \n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(128),\n",
    "    layers.BatchNormalization(),\n",
    "      \n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(64),\n",
    "    \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(16), \n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "  model.compile(loss='msle',\n",
    "                optimizer=optimizer,\n",
    "               )\n",
    "  return model\n",
    "\n",
    "model = build_model03()\n",
    "\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "batch_size = 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, loss:0.1813,  val_loss:144.7977,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:0.0469,  val_loss:120.4040,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:0.0475,  val_loss:121.4320,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:0.0412,  val_loss:129.0302,  \n",
      "....................................................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f426e52d5b0>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=batch_size, epochs=EPOCHS,\n",
    "          verbose=0, validation_data=devs[0],\n",
    "          callbacks=[early_stop, tfdocs.modeling.EpochDots()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 104.4156\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 101.8015\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 102.1837\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 98.0428\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 103.6782\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 101.5779\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 101.8778\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 103.7311\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 100.7103\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 102.5257\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model.evaluate(devs[i][0], devs[i][1], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def f(x, std, mean):\n",
    "    exponent = ((x - mean) / std) ** 2 * (-1) * 0.5\n",
    "    hyp = std * np.sqrt(2 * np.pi)\n",
    "    \n",
    "    return np.exp(exponent) / hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(X_test, batch_size=20, steps=73, verbose=0)\n",
    "pred = pred_y * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It would make sense to convert all of the data to int \n",
    "# instead of float since there no floats in trainig.\n",
    "modified = [] \n",
    "for num in list(pd.DataFrame(pred)[0].values):\n",
    "    if num - int(num) >= 0.5:\n",
    "        modified.append(int(num) + 1)\n",
    "    else:\n",
    "        modified.append(int(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83332, 133333, 157436, 177533, 219502, 173956, 140336, 159178, 185269, 72267]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': test.Id,\n",
    "                      'SalePrice': modified})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
